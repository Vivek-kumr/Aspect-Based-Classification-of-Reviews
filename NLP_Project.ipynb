{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Project.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Penguin2611/Aspect-based-summarization-of-reviews/blob/master/NLP_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abHJknWF_wK0",
        "colab_type": "code",
        "outputId": "7aecf6b3-a85d-443c-c586-75de0b6d8414",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=False)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjxGpe4O-Xrz",
        "colab_type": "code",
        "outputId": "d87b2ce5-b4bf-448b-8a9a-891021f72995",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import pandas as pd\n",
        "import string"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sw9iqcBF--4u",
        "colab_type": "code",
        "outputId": "bcb48fd4-5e46-47aa-9e3a-dd0f3814788f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "## Tokenized Output\n",
        "## object creation\n",
        "stop_words = set(stopwords.words('english'))\n",
        "l = WordNetLemmatizer()\n",
        "t = TweetTokenizer() \n",
        "# stop_words = set(stopwords.words('english'))\n",
        "file = open('/content/drive/My Drive/amazon_review.txt')\n",
        "\n",
        "### Data Reading\n",
        "z = file.readlines()\n",
        "s = \"\"\n",
        "s = s.join(z)\n",
        "\n",
        "\n",
        "### Splitting input lines\n",
        "### Tokenizing line by line\n",
        "\n",
        "for c in string.punctuation:   ### Removing Punctuations\n",
        "    if c == string.punctuation[13]:\n",
        "      s = s.replace(c,\" \")\n",
        "    if c != string.punctuation[6] and c != string.punctuation[12]:\n",
        "      s= s.replace(c,\"\")\n",
        "\n",
        "res = s.splitlines() \n",
        "text = [] \n",
        "for i in res:\n",
        "  p = t.tokenize(i) ### Tokenization\n",
        "  text.append(p)\n",
        "  text.append('\\n')\n",
        "\n",
        "## Flatting the list\n",
        "\n",
        "flat_list = []\n",
        "for sublist in text:\n",
        "    for item in sublist:\n",
        "        flat_list.append(item)\n",
        "\n",
        "tokens = [token.lower() for token in flat_list]\n",
        "tagged = nltk.pos_tag(tokens) ### POS Tagging \n",
        "\n",
        "\n",
        "### Combining list elements to string\n",
        "### Tokenized output\n",
        "\n",
        "### Lemmization\n",
        "lem_text =[]\n",
        "for c in tokens:\n",
        "  tokenize_text = l.lemmatize(c,pos='v')\n",
        "  tokenize_text = l.lemmatize(tokenize_text,pos='n')\n",
        "  tokenize_text = l.lemmatize(tokenize_text,pos='a')\n",
        "  lem_text.append(tokenize_text)\n",
        "\n",
        "### Stopwords Removal\n",
        "stop_text = []\n",
        "for w in lem_text: \n",
        "    if w not in stop_words: \n",
        "        stop_text.append(w) \n",
        "\n",
        "\n",
        "s = \" \"\n",
        "output = s.join(stop_text)\n",
        "print(output)\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "buy even beginner string low quality sound also good go another one upto ₹ 3500 beginner guitar empty dork \n",
            " \n",
            " well beginner guitar know much tell u really satisfy guitar expect something low quality price surprise really good reason want learn guitar \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0076_vSONxT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}